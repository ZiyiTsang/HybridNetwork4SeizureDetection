{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-15T15:38:27.773051Z",
     "start_time": "2024-06-15T15:38:26.408484Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from positional_encodings.torch_encodings import PositionalEncoding1D\n",
    "from einops import rearrange, repeat"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T15:38:27.819984Z",
     "start_time": "2024-06-15T15:38:27.774556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "id": "6b0c8c150df66833",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T15:38:27.835955Z",
     "start_time": "2024-06-15T15:38:27.821344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Classification_block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classification_block, self).__init__()\n",
    "        self.linear_1 = nn.Linear(768, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(256, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.softmax(self.linear_2(self.dropout(self.relu(self.linear_1(x)))))\n",
    "    \n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self,d_in=1365,d_model=768,nhead=6,num_layers=3):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.linear_projection = nn.Linear(d_in, 768)\n",
    "        self.positionEncoding=PositionalEncoding1D(d_model)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead,batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.classification_block = Classification_block()\n",
    "        self.cls_token= nn.Parameter(torch.randn(1,d_model))\n",
    "    def forward(self, x):\n",
    "        x= rearrange(x, 'a b c d -> a d (b c)')\n",
    "        x = self.linear_projection(x)\n",
    "        cls_tokens = repeat(self.cls_token, 'n d -> b n d', b=x.size(0))\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.positionEncoding(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.classification_block(x[:,0,:])\n",
    "        return x"
   ],
   "id": "d959d3601d844885",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T15:38:32.927843Z",
     "start_time": "2024-06-15T15:38:31.441101Z"
    }
   },
   "cell_type": "code",
   "source": "summary(Transformer(d_in=65*22,nhead=6,num_layers=3), input_size=(10, 22, 65,9))",
   "id": "97cf14020dee764e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:685: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  return torch._transformer_encoder_layer_fwd(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "Transformer                                   [10, 2]                   5,514,752\n",
       "├─Linear: 1-1                                 [10, 9, 768]              1,099,008\n",
       "├─PositionalEncoding1D: 1-2                   [10, 10, 768]             --\n",
       "├─TransformerEncoder: 1-3                     [10, 10, 768]             --\n",
       "│    └─ModuleList: 2-1                        --                        --\n",
       "│    │    └─TransformerEncoderLayer: 3-1      [10, 10, 768]             5,513,984\n",
       "│    │    └─TransformerEncoderLayer: 3-2      [10, 10, 768]             5,513,984\n",
       "│    │    └─TransformerEncoderLayer: 3-3      [10, 10, 768]             5,513,984\n",
       "├─Classification_block: 1-4                   [10, 2]                   --\n",
       "│    └─Linear: 2-2                            [10, 256]                 196,864\n",
       "│    └─ReLU: 2-3                              [10, 256]                 --\n",
       "│    └─Dropout: 2-4                           [10, 256]                 --\n",
       "│    └─Linear: 2-5                            [10, 2]                   514\n",
       "│    └─Softmax: 2-6                           [10, 2]                   --\n",
       "===============================================================================================\n",
       "Total params: 23,353,090\n",
       "Trainable params: 23,353,090\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 12.96\n",
       "===============================================================================================\n",
       "Input size (MB): 0.51\n",
       "Forward/backward pass size (MB): 0.57\n",
       "Params size (MB): 5.19\n",
       "Estimated Total Size (MB): 6.27\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T16:49:00.382908Z",
     "start_time": "2024-04-23T16:49:00.135156Z"
    }
   },
   "cell_type": "code",
   "source": "summary(Transformer(d_in=65*22,nhead=8,num_layers=8), input_size=(10, 22, 65,21))",
   "id": "f3b5d694c2e09fa5",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "cd7092246c176f66",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
