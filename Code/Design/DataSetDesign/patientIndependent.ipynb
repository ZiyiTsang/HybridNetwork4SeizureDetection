{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-15T10:05:50.568958Z",
     "start_time": "2024-04-15T10:05:46.126134Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "project_path = os.path.abspath(os.path.relpath('../../../../', os.getcwd()))\n",
    "data_dir= os.path.join(project_path,'BilinearNetwork\\Data\\PreprocessedData\\CHB-MIT\\Prediction')\n",
    "import lightning as L\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T10:05:50.584633Z",
     "start_time": "2024-04-15T10:05:50.570319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_files_plan(data_dir,patient_code,leave_one_code=None):\n",
    "        files = os.listdir(data_dir)\n",
    "        prelix = 'chb'+str(patient_code).zfill(2)\n",
    "        files_filter= [f for f in files if re.match(prelix,f)]\n",
    "        files_preictal = [f for f in files_filter if re.match('.*preictal.*',f)]\n",
    "        files_interictal = [f for f in files_filter if re.match('.*interictal.*',f)]\n",
    "        files_preictal_post=[]\n",
    "        leave_outs=[]\n",
    "        for i in range(len(files_preictal)):\n",
    "            files_preictal_post.append(files_preictal[0:i]+files_preictal[i+1:])\n",
    "            leave_outs.append(files_preictal[i])\n",
    "        assert len(files_interictal)==1\n",
    "        return {'interictal':files_interictal[0],'preictal':files_preictal_post[leave_one_code],'leave_out':leave_outs[leave_one_code]}\n",
    "get_files_plan(data_dir,1,0)"
   ],
   "id": "12b1c6b278814a2e",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T10:05:50.599863Z",
     "start_time": "2024-04-15T10:05:50.585625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "\n",
    "class CHBDependentDMT(L.LightningDataModule):\n",
    "\n",
    "    def __init__(self, data_dir: str ,patient_id:int,leave_out_id:int,batch_size:int=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.data_dir = data_dir\n",
    "        self.patient_id = patient_id\n",
    "        self.leave_out_id = leave_out_id\n",
    "\n",
    "        file_plan=self.get_files_plan(data_dir,patient_id,leave_out_id)\n",
    "        interictal_name,preictal_list,leave_out_name=file_plan['interictal'],file_plan['preictal'],file_plan['leave_out']\n",
    "\n",
    "        interictal_data=np.load(os.path.join(data_dir,interictal_name))\n",
    "        preictal_data_list=[np.load(os.path.join(data_dir,f)) for f in preictal_list]\n",
    "        preictal_data=np.concatenate(preictal_data_list)\n",
    "        leave_out_val_data=np.load(os.path.join(data_dir,leave_out_name))\n",
    "\n",
    "        np.random.shuffle(interictal_data)\n",
    "\n",
    "        interictal_data_train,interictal_data_val=train_test_split(interictal_data,test_size=0.2)\n",
    "\n",
    "        label_test=np.concatenate([np.zeros(len(interictal_data_val)),np.ones(len(leave_out_val_data))])\n",
    "        data_test=np.concatenate([interictal_data_val,leave_out_val_data])\n",
    "\n",
    "        label_fit=np.concatenate([np.zeros(len(interictal_data_train)),np.ones(len(preictal_data))])\n",
    "        data_fit=np.concatenate([interictal_data_train,preictal_data])\n",
    "        X_train,X_valid,y_train,y_valid=train_test_split(data_fit,label_fit,test_size=0.1,shuffle=True)\n",
    "\n",
    "        print('Train Count: Negative {}, Positive {}'.format(len(X_train[y_train==0]),len(X_train[y_train==1])))\n",
    "        print('Validation Count: Negative {}, Positive {}'.format(len(X_valid[y_valid==0]),len(X_valid[y_valid==1])))\n",
    "        print('Test Count: Negative {}, Positive {}'.format(len(data_test[label_test==0]),len(data_test[label_test==1]))\n",
    "        )\n",
    "\n",
    "        self.trainset = TensorDataset(torch.tensor(X_train,dtype=torch.float32),torch.tensor(y_train,dtype=torch.float32))\n",
    "        self.valset = TensorDataset(torch.tensor(X_valid,dtype=torch.float32),torch.tensor(y_valid,dtype=torch.float32))\n",
    "        self.testset = TensorDataset(torch.tensor(data_test,dtype=torch.float32),torch.tensor(label_test,dtype=torch.float32))\n",
    "\n",
    "        del interictal_data,preictal_data,leave_out_val_data,interictal_data_train,interictal_data_val,label_test,data_test,label_fit,data_fit,X_train,X_valid,y_train,y_valid\n",
    "\n",
    "    def get_files_plan(self,data_dir,patient_code,leave_one_code=None):\n",
    "        files = os.listdir(data_dir)\n",
    "        prelix = 'chb'+str(patient_code).zfill(2)\n",
    "        files_filter= [f for f in files if re.match(prelix,f)]\n",
    "        files_preictal = [f for f in files_filter if re.match('.*preictal.*',f)]\n",
    "        files_interictal = [f for f in files_filter if re.match('.*interictal.*',f)]\n",
    "        files_preictal_post=[]\n",
    "        leave_outs=[]\n",
    "        for i in range(len(files_preictal)):\n",
    "            files_preictal_post.append(files_preictal[0:i]+files_preictal[i+1:])\n",
    "            leave_outs.append(files_preictal[i])\n",
    "        assert len(files_interictal)==1\n",
    "        return {'interictal':files_interictal[0],'preictal':files_preictal_post[leave_one_code],'leave_out':leave_outs[leave_one_code]}\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        pass\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.trainset, batch_size=self.batch_size,shuffle=True,pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.valset, batch_size=self.batch_size,shuffle=True,pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.testset, batch_size=self.batch_size,shuffle=True,pin_memory=True)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return None"
   ],
   "id": "92bec16c6a7b0aa5",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T10:05:52.478906Z",
     "start_time": "2024-04-15T10:05:50.600860Z"
    }
   },
   "cell_type": "code",
   "source": "dm=CHBDependentDMT(data_dir=data_dir,patient_id=1,leave_out_id=0,batch_size=32)",
   "id": "427edcb33c3d1800",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:43:24.386106Z",
     "start_time": "2024-04-15T08:43:24.371105Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9238887938cb4f52",
   "execution_count": 5,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
