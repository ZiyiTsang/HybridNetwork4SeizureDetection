{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-08T16:55:24.105771Z",
     "start_time": "2024-04-08T16:55:23.521053Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "sys.path.append('../../')\n",
    "\n",
    "project_path = os.path.abspath(os.path.relpath('../../../../', os.getcwd()))\n",
    "preprocessed_path=os.path.join(project_path,'BilinearNetwork/Data/PreprocessedData/CHB-MIT/STFT/')\n",
    "save_folder=os.path.join(project_path,'BilinearNetwork/Data/PreprocessedData/CHB-MIT/Concanate/')"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Merge the preictal and interictal files to STFT folder",
   "id": "8b55d35159880da7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T16:56:23.946856Z",
     "start_time": "2024-04-08T16:55:24.107275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "def merge_patient_files(root_folder):\n",
    "    for i in tqdm(range(1,25)):  # 遍历从chb00到chb24的文件\n",
    "        patient_id = \"chb{:02d}\".format(i)  # 根据索引生成病人编号\n",
    "        preictal_filename = patient_id + \"_preictal.npz\"\n",
    "        interictal_filename = patient_id + \"_interictal.npz\"\n",
    "\n",
    "        if os.path.exists(os.path.join(root_folder, preictal_filename)) and \\\n",
    "                os.path.exists(os.path.join(root_folder, interictal_filename)):\n",
    "            # 读取数据\n",
    "            preictal_data = np.load(os.path.join(root_folder, preictal_filename))['data']\n",
    "            preictal_label = np.load(os.path.join(root_folder, preictal_filename))['label']\n",
    "            interictal_data = np.load(os.path.join(root_folder, interictal_filename))['data']\n",
    "            interictal_label = np.load(os.path.join(root_folder, interictal_filename))['label']\n",
    "\n",
    "            # 合并数据和标签\n",
    "            merged_data = np.concatenate((preictal_data, interictal_data), axis=0).astype(np.float32)\n",
    "            merged_label = np.concatenate((preictal_label, interictal_label), axis=0).astype(np.float32)\n",
    "\n",
    "            # 洗牌\n",
    "            merged_data, merged_label = shuffle(merged_data, merged_label)\n",
    "\n",
    "            # 保存到新文件\n",
    "            save_path = os.path.join(save_folder, patient_id + \".npz\")\n",
    "            np.savez(save_path, data=merged_data, label=merged_label)\n",
    "\n",
    "            # os.remove(os.path.join(root_folder, preictal_filename))\n",
    "            # os.remove(os.path.join(root_folder, interictal_filename))\n",
    "\n",
    "\n",
    "merge_patient_files(preprocessed_path)\n"
   ],
   "id": "c5fc5c98785e6ff4",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Build the folder and move the files into train/test folder",
   "id": "ac6847c5df09f84c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T16:56:23.962403Z",
     "start_time": "2024-04-08T16:56:23.948411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_folder_train=os.path.join(project_path,'BilinearNetwork/Data/PreprocessedData/CHB-MIT/Concanate/Train/')\n",
    "save_folder_test=os.path.join(project_path,'BilinearNetwork/Data/PreprocessedData/CHB-MIT/Concanate/Test/')\n",
    "save_folder_valid=os.path.join(project_path,'BilinearNetwork/Data/PreprocessedData/CHB-MIT/Concanate/Valid/')\n",
    "if not os.path.exists(save_folder_train):\n",
    "    os.makedirs(save_folder_train)\n",
    "if not os.path.exists(save_folder_test):\n",
    "    os.makedirs(save_folder_test)\n",
    "if not os.path.exists(save_folder_valid):\n",
    "    os.makedirs(save_folder_valid)"
   ],
   "id": "7f63397835460f54",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T16:56:23.977139Z",
     "start_time": "2024-04-08T16:56:23.964932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import shutil\n",
    "test_patient=['chb04','chb06','chb10','chb19']\n",
    "for file in [f for f in os.listdir(save_folder) if f.endswith('.npz')]:\n",
    "    patient_id=file.split('.')[0]\n",
    "\n",
    "    if patient_id in test_patient:\n",
    "        shutil.move(os.path.join(save_folder,file),os.path.join(save_folder_test,file))\n",
    "    else:\n",
    "        shutil.move(os.path.join(save_folder,file),os.path.join(save_folder_train,file))"
   ],
   "id": "8e1097ac558c6e32",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Slicing",
   "id": "c259bb3f555a0488"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T16:57:11.263353Z",
     "start_time": "2024-04-08T16:56:23.978646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "def split_npz_files(input_folder, output_folder, samples_per_file=20000):\n",
    "    # 创建输出文件夹\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # 获取输入文件夹下的所有npz文件\n",
    "    npz_files = [f for f in os.listdir(input_folder) if f.endswith('.npz')]\n",
    "    npz_files.sort()  # 确保文件按顺序处理\n",
    "\n",
    "    current_samples = []  # 当前正在处理的样本\n",
    "    current_file_index = 0  # 当前输出文件编号\n",
    "\n",
    "    for npz_file in tqdm(npz_files):\n",
    "        # 加载npz文件\n",
    "        data = np.load(os.path.join(input_folder, npz_file))\n",
    "        samples, labels = data['data'], data['label']\n",
    "\n",
    "        # 将当前npz文件中的样本加入到当前正在处理的样本列表中\n",
    "        current_samples.extend(zip(samples, labels))\n",
    "\n",
    "        # 如果当前样本数量达到或超过了指定的每个文件的样本数量\n",
    "        while len(current_samples) >= samples_per_file:\n",
    "            # 创建一个新的npz文件\n",
    "            output_filename = f\"data_{current_file_index}.npz\"\n",
    "            output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "            # 从当前样本列表中取出指定数量的样本\n",
    "            batch_samples = current_samples[:samples_per_file]\n",
    "            current_samples = current_samples[samples_per_file:]\n",
    "\n",
    "            # 将样本拆分为data和label\n",
    "            batch_data, batch_labels = zip(*batch_samples)\n",
    "\n",
    "            # 保存样本到新的npz文件\n",
    "            np.savez(output_path, data=np.array(batch_data), label=np.array(batch_labels))\n",
    "\n",
    "            # 更新当前输出文件编号\n",
    "            current_file_index += 1\n",
    "\n",
    "    # 处理最后剩余的样本\n",
    "    if current_samples:\n",
    "        output_filename = f\"data_{current_file_index}.npz\"\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "        batch_data, batch_labels = zip(*current_samples)\n",
    "        np.savez(output_path, data=np.array(batch_data), label=np.array(batch_labels))\n",
    "\n",
    "# 调用函数\n",
    "# split_npz_files(save_folder_test, save_folder_test)\n",
    "split_npz_files(save_folder_train, save_folder_train)"
   ],
   "id": "5d369f0ce9bbf6f6",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Delete intermediate files",
   "id": "7039f071df960119"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T16:57:11.896208Z",
     "start_time": "2024-04-08T16:57:11.265499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def delete_files(folder):\n",
    "    for file in [f for f in os.listdir(folder) if f.endswith('.npz')]:\n",
    "        if file.startswith('chb'):\n",
    "            os.remove(os.path.join(folder, file))\n",
    "# delete_files(save_folder_test)\n",
    "delete_files(save_folder_train)"
   ],
   "id": "64d398f3a3056dee",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Validate any file",
   "id": "469a8338c2c40ca5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T16:57:11.912058Z",
     "start_time": "2024-04-08T16:57:11.897355Z"
    }
   },
   "cell_type": "code",
   "source": "# np.load(\"E:\\Research\\BilinearNetwork\\Data\\PreprocessedData\\CHB-MIT\\Concanate\\Train\\data_0.npz\")['label'][:20]",
   "id": "e3223bd7dde4abf",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Valid Set",
   "id": "96f0901d58cc6fdd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d670c0ad32c039f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T16:57:29.482666Z",
     "start_time": "2024-04-08T16:57:11.914064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def combineValidSet(num_leave_out=500):\n",
    "    file_list = os.listdir(save_folder_train)\n",
    "    datas = None\n",
    "    labels = None\n",
    "    for file_name in tqdm(file_list):\n",
    "        file = np.load(os.path.join(save_folder_train, file_name), mmap_mode='r', allow_pickle=False)\n",
    "        local_data=file['data']\n",
    "        local_labels=file['label']\n",
    "        sample=len(local_data)\n",
    "        del file\n",
    "        if datas is None:\n",
    "            datas=local_data[sample-num_leave_out:]\n",
    "            labels=local_labels[sample-num_leave_out:]\n",
    "        else:\n",
    "            datas=np.concatenate([datas,local_data[sample-num_leave_out:]])\n",
    "            labels=np.concatenate([labels,local_labels[sample-num_leave_out:]])\n",
    "        print(datas.shape)\n",
    "        del local_data,local_labels\n",
    "    np.savez(os.path.join(save_folder_valid,\"valid_data.npz\"),data=datas,label=labels)\n",
    "combineValidSet()"
   ],
   "id": "f3adb1b95fbb2be0",
   "execution_count": 8,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
